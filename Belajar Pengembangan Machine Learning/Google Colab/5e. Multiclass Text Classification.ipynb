{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5e. Multiclass Text Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNSmHdpeRn4de192c5O2qQ9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kcBYw83_ri9M"},"source":["Pada latihan kali ini kita akan melakukan klasifikasi teks multikelas menggunakan lstm.\n","\n","Pada latihan ini kita akan menggunakan dataset yang berisi sinopsis dari beberapa film Indonesia dan genrenya. Tujuan kita adalah menentukan genre sebuah film berdasarkan sinopsisnya. Dataset dapat Anda unduh pada [tautan](https://www.kaggle.com/antoniuscs/imdb-synopsis-indonesian-movies) berikut."]},{"cell_type":"markdown","metadata":{"id":"M-U2xT_mrsUU"},"source":["Pada cell pertama impor library pandas dan ubah dataset menjadi dataframe. Kemudian buang kolom 'judul_film' karena kita hanya akan menggunakan sinopsis sebagai atribut untuk dilatih pada model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"d8s-eq76rhc_","executionInfo":{"elapsed":321,"status":"ok","timestamp":1632303971100,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"},"user_tz":-420},"outputId":"ed752efd-e2ed-4817-8c27-c640c05d7fb9"},"source":["import pandas as pd\n","df = pd.read_csv('/content/imdb_indonesian_movies.csv')\n","df = df.drop(columns=['judul_film'])\n","\n","# Panggil fungsi head() pada dataframe untuk menampilkan 5 sampel teratas pada dataset.\n","df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ringkasan_sinopsis</th>\n","      <th>genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raden Mas Said putra sulung Tumenggung Wilarik...</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Soe Hok Gie adalah seorang aktivis yang hidup ...</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Guru Bangsa Tjokroaminoto menceritakan tentang...</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>POL menceritakan kisah hidup yang luar biasa d...</td>\n","      <td>Drama</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Perjalanan pahlawan Indonesia KH Ahmad Dahlan ...</td>\n","      <td>Drama</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  ringkasan_sinopsis  genre\n","0  Raden Mas Said putra sulung Tumenggung Wilarik...  Drama\n","1  Soe Hok Gie adalah seorang aktivis yang hidup ...  Drama\n","2  Guru Bangsa Tjokroaminoto menceritakan tentang...  Drama\n","3  POL menceritakan kisah hidup yang luar biasa d...  Drama\n","4  Perjalanan pahlawan Indonesia KH Ahmad Dahlan ...  Drama"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"Z4XooRWPsOKN"},"source":["Karena label kita berupa data kategorikal, maka kita perlu melakukan proses **one-hot-encoding**. Jalankan kode di bawah untuk melakukan one-hot-encoding dan membuat dataframe baru."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"MbIZBrUNsXXi","executionInfo":{"elapsed":7,"status":"ok","timestamp":1632303971636,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"},"user_tz":-420},"outputId":"bcf62a8b-bd43-4dc7-b2ba-7dd8f42172b2"},"source":["category = pd.get_dummies(df.genre)\n","df_baru = pd.concat([df, category], axis=1)\n","df_baru = df_baru.drop(columns='genre')\n","df_baru"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ringkasan_sinopsis</th>\n","      <th>Drama</th>\n","      <th>Horor</th>\n","      <th>Komedi</th>\n","      <th>Laga</th>\n","      <th>Romantis</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Raden Mas Said putra sulung Tumenggung Wilarik...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Soe Hok Gie adalah seorang aktivis yang hidup ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Guru Bangsa Tjokroaminoto menceritakan tentang...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>POL menceritakan kisah hidup yang luar biasa d...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Perjalanan pahlawan Indonesia KH Ahmad Dahlan ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1000</th>\n","      <td>Winter in Tokyo berpusat pada kehidupan Ishida...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1001</th>\n","      <td>Markonah melarikan diri ke Jakarta karena akan...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1002</th>\n","      <td>Tempat aking lebih dari 36 jam, Last Night ada...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1003</th>\n","      <td>Proyek baru ini adalah tentang seorang lelaki ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1004</th>\n","      <td>Atika (Meriam Bellina) mantan penyanyi tenar, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1005 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["                                     ringkasan_sinopsis  Drama  ...  Laga  Romantis\n","0     Raden Mas Said putra sulung Tumenggung Wilarik...      1  ...     0         0\n","1     Soe Hok Gie adalah seorang aktivis yang hidup ...      1  ...     0         0\n","2     Guru Bangsa Tjokroaminoto menceritakan tentang...      1  ...     0         0\n","3     POL menceritakan kisah hidup yang luar biasa d...      1  ...     0         0\n","4     Perjalanan pahlawan Indonesia KH Ahmad Dahlan ...      1  ...     0         0\n","...                                                 ...    ...  ...   ...       ...\n","1000  Winter in Tokyo berpusat pada kehidupan Ishida...      0  ...     0         1\n","1001  Markonah melarikan diri ke Jakarta karena akan...      0  ...     0         1\n","1002  Tempat aking lebih dari 36 jam, Last Night ada...      0  ...     0         1\n","1003  Proyek baru ini adalah tentang seorang lelaki ...      0  ...     0         1\n","1004  Atika (Meriam Bellina) mantan penyanyi tenar, ...      0  ...     0         1\n","\n","[1005 rows x 6 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"stciPBj1suLw"},"source":["Agar dapat diproses oleh model, kita perlu mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values."]},{"cell_type":"code","metadata":{"id":"iqd7zkG5svig"},"source":["sinopsis = df_baru['ringkasan_sinopsis'].values\n","label = df_baru[['Drama', 'Horor', 'Komedi', 'Laga', 'Romantis']].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OVeAJLRAtCnk"},"source":["Lalu, bagi data untuk training dan data untuk testing."]},{"cell_type":"code","metadata":{"id":"1oDSJqlMtDAx"},"source":["from sklearn.model_selection import train_test_split\n","sinopsis_latih, sinopsis_test, label_latih, label_test = train_test_split(sinopsis, label, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQTBj9C-tci1"},"source":["Kemudian kita ubah setiap kata pada dataset kita ke dalam bilangan numerik dengan fungsi Tokenizer. Setelah tokenisasi selesai, kita perlu membuat mengonversi setiap sampel menjadi sequence."]},{"cell_type":"code","metadata":{"id":"Ux6vEf8CtfF5"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","tokenizer = Tokenizer(num_words=5000, oov_token='x')\n","tokenizer.fit_on_texts(sinopsis_latih)\n","tokenizer.fit_on_texts(sinopsis_test)\n","\n","sekuens_latih = tokenizer.texts_to_sequences(sinopsis_latih)\n","sekuens_test = tokenizer.texts_to_sequences(sinopsis_test)\n","\n","padded_latih = pad_sequences(sekuens_latih)\n","padded_test = pad_sequences(sekuens_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gg19BxN-uHQA"},"source":["Untuk arsitektur model kita menggunakan layer Embedding dengan dimensi embedding sebesar '16', serta dimensi dari input sebesar nilai `num_words` pada objek tokenizer. Jangan lupa panggil fungsi `compile` dan tentukan optimizer serta loss function yang akan dipakai oleh model."]},{"cell_type":"code","metadata":{"id":"SJDTzHMouMow"},"source":["import tensorflow as tf\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),\n","    tf.keras.layers.LSTM(64),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(5, activation='softmax'),\n","])\n","\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uefIG5CCu6K9"},"source":["Terakhir kita dapat mulai melatih model kita dengan memanggil fungsi `fit()`."]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"G5ehit_Hu7Wo","outputId":"f5d75899-f47c-4b1a-b24e-e215817f8d5e"},"source":["num_epochs = 30\n","history = model.fit(padded_latih, label_latih, epochs=num_epochs,\n","                    validation_data=(padded_test, label_test), verbose=2)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","26/26 - 31s - loss: 1.6101 - accuracy: 0.1803 - val_loss: 1.6099 - val_accuracy: 0.1891\n","Epoch 2/30\n","26/26 - 27s - loss: 1.6060 - accuracy: 0.2214 - val_loss: 1.6077 - val_accuracy: 0.1990\n","Epoch 3/30\n","26/26 - 28s - loss: 1.5643 - accuracy: 0.3396 - val_loss: 1.6142 - val_accuracy: 0.2139\n","Epoch 4/30\n","26/26 - 27s - loss: 1.3161 - accuracy: 0.4279 - val_loss: 1.8352 - val_accuracy: 0.2736\n","Epoch 5/30\n","26/26 - 28s - loss: 0.9642 - accuracy: 0.5908 - val_loss: 2.4760 - val_accuracy: 0.2289\n","Epoch 6/30\n","26/26 - 28s - loss: 0.6068 - accuracy: 0.7861 - val_loss: 2.2634 - val_accuracy: 0.2935\n","Epoch 7/30\n","26/26 - 28s - loss: 0.2808 - accuracy: 0.9291 - val_loss: 2.9210 - val_accuracy: 0.3333\n","Epoch 8/30\n","26/26 - 28s - loss: 0.1119 - accuracy: 0.9739 - val_loss: 3.4293 - val_accuracy: 0.3333\n","Epoch 9/30\n","26/26 - 27s - loss: 0.0505 - accuracy: 0.9900 - val_loss: 3.9139 - val_accuracy: 0.3035\n","Epoch 10/30\n","26/26 - 28s - loss: 0.0590 - accuracy: 0.9863 - val_loss: 3.0011 - val_accuracy: 0.3134\n","Epoch 11/30\n","26/26 - 28s - loss: 0.1338 - accuracy: 0.9714 - val_loss: 3.0297 - val_accuracy: 0.2836\n","Epoch 12/30\n","26/26 - 28s - loss: 0.0471 - accuracy: 0.9925 - val_loss: 3.5097 - val_accuracy: 0.3085\n","Epoch 13/30\n","26/26 - 28s - loss: 0.0271 - accuracy: 0.9938 - val_loss: 3.6001 - val_accuracy: 0.3035\n","Epoch 14/30\n","26/26 - 27s - loss: 0.0165 - accuracy: 0.9988 - val_loss: 3.8640 - val_accuracy: 0.2886\n","Epoch 15/30\n","26/26 - 28s - loss: 0.0124 - accuracy: 0.9975 - val_loss: 3.9782 - val_accuracy: 0.2985\n","Epoch 16/30\n","26/26 - 28s - loss: 0.0110 - accuracy: 0.9988 - val_loss: 4.0289 - val_accuracy: 0.3134\n","Epoch 17/30\n","26/26 - 27s - loss: 0.0107 - accuracy: 0.9988 - val_loss: 4.1317 - val_accuracy: 0.2836\n","Epoch 18/30\n","26/26 - 27s - loss: 0.0115 - accuracy: 0.9988 - val_loss: 4.1433 - val_accuracy: 0.3234\n","Epoch 19/30\n","26/26 - 27s - loss: 0.0099 - accuracy: 0.9975 - val_loss: 4.1101 - val_accuracy: 0.3184\n","Epoch 20/30\n","26/26 - 28s - loss: 0.0073 - accuracy: 0.9988 - val_loss: 4.1743 - val_accuracy: 0.3035\n","Epoch 21/30\n","26/26 - 28s - loss: 0.0065 - accuracy: 0.9975 - val_loss: 4.2091 - val_accuracy: 0.3035\n","Epoch 22/30\n","26/26 - 28s - loss: 0.0112 - accuracy: 0.9975 - val_loss: 4.1813 - val_accuracy: 0.3085\n","Epoch 23/30\n","26/26 - 27s - loss: 0.0054 - accuracy: 0.9988 - val_loss: 4.2465 - val_accuracy: 0.3085\n","Epoch 24/30\n","26/26 - 27s - loss: 0.0062 - accuracy: 0.9988 - val_loss: 4.3007 - val_accuracy: 0.3035\n","Epoch 25/30\n","26/26 - 27s - loss: 0.0062 - accuracy: 0.9988 - val_loss: 4.2795 - val_accuracy: 0.3134\n","Epoch 26/30\n","26/26 - 28s - loss: 0.0065 - accuracy: 0.9988 - val_loss: 4.2741 - val_accuracy: 0.2935\n","Epoch 27/30\n","26/26 - 27s - loss: 0.0058 - accuracy: 0.9975 - val_loss: 4.2999 - val_accuracy: 0.3035\n","Epoch 28/30\n","26/26 - 28s - loss: 0.0080 - accuracy: 0.9988 - val_loss: 4.2654 - val_accuracy: 0.3035\n","Epoch 29/30\n","26/26 - 28s - loss: 0.0038 - accuracy: 0.9988 - val_loss: 4.3792 - val_accuracy: 0.3284\n","Epoch 30/30\n","26/26 - 28s - loss: 0.0077 - accuracy: 0.9975 - val_loss: 4.3439 - val_accuracy: 0.3035\n"]}]},{"cell_type":"markdown","metadata":{"id":"pd8UAPLGvVpO"},"source":["Akurasi dari model kita menunjukkan terjadinya **overfitting** karena akurasi pada data testing sangat besar, sedangkan akurasi pada data validasi jauh lebih kecil. Hal ini masih sangat luar biasa karena kita hanya memiliki 1000 buah sampel data!"]},{"cell_type":"markdown","metadata":{"id":"AyLCg4g3vdJB"},"source":["# Selamat! Anda telah paham bagaimana mengembangkan model ML untuk salah satu kasus NLP yaitu klasifikasi teks. Anda telah paham bagaimana memproses teks, serta menggunakan Embedding dan LSTM layer pada arsitektur modul Anda. \n","\n","# Setelah submodul ini Anda harus menyelesaikan submission pertama Anda tentang NLP agar bisa mengakses materi-materi selanjutnya.\n","# Semangat!"]}]}