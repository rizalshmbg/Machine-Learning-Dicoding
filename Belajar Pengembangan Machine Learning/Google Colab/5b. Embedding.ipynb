{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5b. Embedding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFW5b3Ye+lNehPwninjkaM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"V48At7cUt92Q"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxU4mQWYupvb"},"source":["tokenizer = Tokenizer(num_words=15, oov_token='-')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zyttg7PmvPs8"},"source":["teks = ['Saya suka programming',\n","        'Programming sangat menyenangkan',\n","        'Machine Learning berbeda dengan pemrograman konvesional']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76m5RqD7vhIU"},"source":["tokenizer.fit_on_texts(teks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnMIbDKsvpdU"},"source":["sequences = tokenizer.texts_to_sequences(teks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"johQAiVHv6Rq","executionInfo":{"status":"ok","timestamp":1632279132952,"user_tz":-420,"elapsed":57,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"}},"outputId":"166218a2-f8ca-4aff-e7b5-a6a8fe4f37a9"},"source":["print(tokenizer.word_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'-': 1, 'programming': 2, 'saya': 3, 'suka': 4, 'sangat': 5, 'menyenangkan': 6, 'machine': 7, 'learning': 8, 'berbeda': 9, 'dengan': 10, 'pemrograman': 11, 'konvesional': 12}\n"]}]},{"cell_type":"code","metadata":{"id":"MPrmeZpPwcWD"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","sequences_samapanjang = pad_sequences(sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYBNFhYlwr7j","executionInfo":{"status":"ok","timestamp":1632279132957,"user_tz":-420,"elapsed":47,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"}},"outputId":"cf20957d-5489-428b-c343-20fc0b70b9df"},"source":["print(sequences_samapanjang)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  3  4  2]\n"," [ 0  0  0  2  5  6]\n"," [ 7  8  9 10 11 12]]\n"]}]},{"cell_type":"code","metadata":{"id":"8xDfX39Rwxyt"},"source":["sequences_samapanjang = pad_sequences(sequences,\n","                                      padding='post',\n","                                      maxlen=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXKA-TSUxHbl"},"source":["sequences_samapanjang = pad_sequences(sequences, \n","                                      padding='post',\n","                                      maxlen=5,\n","                                      truncating='post')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TShg-P2Xx7Jk"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"4Yc0ByLvxkP8"},"source":["Pada submodul sebelumnya kita telah belajar bagaimana mengubah teks menjadi sequence berisi nilai-nilai yang merepresentasikan setiap kata pada kalimat. Lalu apa tahapan lanjut yang perlu kita lakukan dalam klasifikasi NLP?\n","\n","Pada klasifikasi teks, kita perlu melakukan **embedding** yang merupakan kunci dalam klasifikasi teks di Tensorflow. **Embedding** memungkinkan model ML untuk memahami makna di setiap kata dan mengelompokkan kata-kata dengan makna yang mirip agar berdekatan. Misalnya komentar pada sebuah video youtube, di mana kata-kata “menarik”, “keren”, dan “luar biasa” akan dikelompokkan berdekatan. Pengelompokkan ini dapat dicapai dengan memetakan setiap kata ke dalam vektor atau larik. Di mana kata yang mirip akan memiliki nilai vektor yang mirip. \n","\n","Makna dari sebuah kata didapat dari label dari data tersebut. Misalnya pada teks yang berlabel negatif terdapat banyak kata ‘membosankan’, dan ‘jelek’. Maka kedua kata tersebut memiliki makna yang mirip sehingga nilai vektor mereka mirip. Informasi lebih detail mengenai Embedding dapat Anda lihat pada [tautan berikut](https://www.tensorflow.org/text/guide/word_embeddings)"]},{"cell_type":"markdown","metadata":{"id":"9ZwUIOC4xuwM"},"source":["Untuk mengimplementasikan Embedding pada Keras juga sangatlah mudah. Pada model sequential, kita tinggal memanggil fungsi `embedding()` dan mengisi parameter total kata yang di tokenisasi, panjang kalimat, serta dimensi embedding yang diinginkan. Karena hasil dari embedding merupakan larik 2 dimensi yang berisi panjang setiap kalimat, dan dimensi embedding, maka kita memerlukan fungsi `flatten()`."]},{"cell_type":"code","metadata":{"id":"RS9Amif6xi-8","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1632279389134,"user_tz":-420,"elapsed":372,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"}},"outputId":"03151d27-d2d2-4025-fc4e-8dcabcbc6d65"},"source":["import tensorflow as tf\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(jumlah_kata, dimensi_embedding, panjang_input),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-48944022f562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model = tf.keras.Sequential([\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjumlah_kata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensi_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpanjang_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'jumlah_kata' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"WlkIKk9VdSSQ"},"source":["Setelah mengimplementasikan Embedding pada model sekuensial kita, panggil fungsi `compile`. Untuk optimizer, kita dapat menggunakan optimizer yang telah kita pelajari sebelumnya. Sedangkan loss disesuaikan dengan kelas yang terdapat pada dataset. "]},{"cell_type":"code","metadata":{"id":"KE7tKbTTdVfa"},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rh6Tij_9dXpa"},"source":["Untuk fungsi `fit`, kita memerlukan parameter teks yang telah di-padding, label dari data training, jumlah epoch, serta data validasi. Mudah bukan."]},{"cell_type":"code","metadata":{"id":"DC8icN_kdbID"},"source":["model.fit(padded_latih, label_latih, \n","          epochs=num_epochs, \n","          validation_data=(padded_test, label_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v5KX06SpdclP"},"source":["# Sampai di sini, kita telah memahami tahapan dalam mengembangkan model untuk klasifikasi teks. Dapat dilihat pada penjelasan sebelumnya bahwa pengembangan model untuk NLP tidak jauh berbeda dengan kasus klasifikasi gambar. Di submodul selanjutnya kita akan latihan dengan mengimplementasikan model untuk klasifikasi teks 2 kelas."]}]}