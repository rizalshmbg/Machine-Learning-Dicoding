{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5a. Latihan Tokenization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTPr7ye+XLOqiAM90Yy5W/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qUlZg_NBt_X1"},"source":["Pada latihan kali ini kita akan belajar bagaimana melakukan **tokenization** dan membuat sequence dari teks kita. Untuk menggunakan tokenizer, impor library di bawah"]},{"cell_type":"code","metadata":{"id":"V48At7cUt92Q"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c2_SobF0uRuO"},"source":["Kemudian buat objek tokenizer dengan memanggil fungsi `tokenizer` dan melengkapi parameternya. Parameter `num_words` adalah jumlah kata yang akan dikonversi ke dalam token/bilangan numerik. Jika parameter `num_words` diisi 15, maka hanya 15 huruf yang paling sering muncul akan ditokenisasi dari seluruh kata pada dataset. \n","\n","Sedangkan parameter `oov_token` adalah parameter yang berfungsi untuk mengganti kata-kata yang tidak ditokenisasi menjadi karakter tertentu. Pada praktiknya, lebih baik untuk mengganti kata yang tidak dikenali dengan suatu kata tertentu dibanding melewatkan kata tersebut untuk mengurangi informasi yang hilang. Hal inilah yang dapat dilakukan dengan menambahkan parameter 'OOV'."]},{"cell_type":"code","metadata":{"id":"fxU4mQWYupvb"},"source":["tokenizer = Tokenizer(num_words=15, oov_token='-')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dysgQYTKvO-m"},"source":["Lalu, buat teks yang akan kita tokenisasi dan kita pakai untuk pelatihan model. "]},{"cell_type":"code","metadata":{"id":"zyttg7PmvPs8"},"source":["teks = ['Saya suka programming',\n","        'Programming sangat menyenangkan',\n","        'Machine Learning berbeda dengan pemrograman konvesional']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAQUG9cGvc80"},"source":["Untuk melakukan tokenisasi, panggil fungsi `fit_on_text()` pada objek tokenizer dan isi teks kita sebagai argumennya."]},{"cell_type":"code","metadata":{"id":"76m5RqD7vhIU"},"source":["tokenizer.fit_on_texts(teks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ubzvasKrvnFs"},"source":["Kemudian, kita akan mengubah kalimat ke dalam nilai yang sesuai dengan fungsi `texts_to_sequences`."]},{"cell_type":"code","metadata":{"id":"JnMIbDKsvpdU"},"source":["sequences = tokenizer.texts_to_sequences(teks)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-hl4yJSvvlt"},"source":["Untuk melihat hasil tokenisasi, kita bisa memanggil atribut `word_index` dari objek tokenizer. Atribut `word_index` mengembalikan dictionary berupa kata sebagai key dan token atau nilai numeriknya sebagai value. Perlu diperhatikan bahwa tanda baca dan huruf kapital tidak diproses oleh tokenizer. Contohnya kata “Selamat!” dan “SELAMAT” akan diperlakukan sebagai kata yang sama. Hasil dari cell di bawah menunjukkan bahwa kata-kata yang out-of-vocabulary akan diberi token bernilai 1. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"johQAiVHv6Rq","executionInfo":{"status":"ok","timestamp":1632234362965,"user_tz":-420,"elapsed":452,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"}},"outputId":"25298782-0ef7-4b67-b7e5-1dedf7be202c"},"source":["print(tokenizer.word_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'-': 1, 'programming': 2, 'saya': 3, 'suka': 4, 'sangat': 5, 'menyenangkan': 6, 'machine': 7, 'learning': 8, 'berbeda': 9, 'dengan': 10, 'pemrograman': 11, 'konvesional': 12}\n"]}]},{"cell_type":"markdown","metadata":{"id":"-a-M0qeYwFQ8"},"source":["Setelah tokenisasi, untuk mengubah kalimat ke dalam nilai-nilai yang sesuai dapat dengan menggunakan fungsi `text_to_sequence`() dan masukkan parameter dari teks kita. Ketika sequence telah dibuat, hal yang perlu kita lakukan adalah **padding**. Yup, padding adalah proses untuk membuat setiap kalimat pada teks memiliki panjang yang seragam. Sama seperti melakukan resize gambar, agar resolusi setiap gambar sama besar. Untuk menggunakan padding impor library `pad_sequence`. Kemudian buat panggil fungsi `pad_sequence`() dan masukkan sequence hasil tokenisasi sebagai parameternya."]},{"cell_type":"code","metadata":{"id":"MPrmeZpPwcWD"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","sequences_samapanjang = pad_sequences(sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fpdue-NQwpul"},"source":["Hasil setelah padding adalah setiap sequence memiliki panjang yang sama. Padding dapat melakukan ini dengan menambahkan 0 secara default pada awal sequence yang lebih pendek."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYBNFhYlwr7j","executionInfo":{"status":"ok","timestamp":1632234573430,"user_tz":-420,"elapsed":450,"user":{"displayName":"Rizal Sihombing","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHdaFgVUUc0oj1CRMgNMsZ6dVCXXiXl88lNlBLDw=s64","userId":"15325755837778064720"}},"outputId":"72b7d9f5-9e2b-4507-9be3-6482b013bf39"},"source":["print(sequences_samapanjang)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0  3  4  2]\n"," [ 0  0  0  2  5  6]\n"," [ 7  8  9 10 11 12]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"fViFREn8wy0V"},"source":["Jika kita ingin merubah sehingga 0 ditambahkan di akhir sequence, kita dapat menggunakan parameter padding dengan nilai ‘post’. Selain itu kita dapat mengatur berapa maksimum panjang setiap sequence dengan parameter `maxlen` dan nilai yang kita inginkan. Jika kita mengisi nilai 5, maka panjang sebuah sequence tidak akan melebihi 5. "]},{"cell_type":"code","metadata":{"id":"8xDfX39Rwxyt"},"source":["sequences_samapanjang = pad_sequences(sequences,\n","                                      padding='post',\n","                                      maxlen=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BJchNb4Vw_xF"},"source":["Jika teks kita memiliki panjang lebih dari nilai parameter `maxlen` misalnya 5, maka secara default nilai dari sequence akan diambil 5 nilai terakhir atau 5 kata terakhir saja dari setiap kalimat. Untuk mengubah pengaturan ini dan mengambil 5 kata terakhir dari tiap kalimat, kita dapat menggunakan parameter `truncating` dan mengisi nilai ‘post’."]},{"cell_type":"code","metadata":{"id":"AXKA-TSUxHbl"},"source":["sequences_samapanjang = pad_sequences(sequences, \n","                                      padding='post',\n","                                      maxlen=5,\n","                                      truncating='post')"],"execution_count":null,"outputs":[]}]}